---
title: "Multivariate Data Analysis - chapter 04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(python = reticulate::eng_python)
```

# 4.군집분석

## 1. 군집분석이란?

## 2. 유사성 측도

-   두 관찰치 사이의 유사성 측도: 측정방법에 따라 거리(distance)와 유사성(similarity)으로 구분

    -   거리: 값이 작을수록 두 관찰치가 서로 유사

    -   유사성: 값이 클수록 두 관찰치가 서로 유사한 것을 의미

-   유클리디안(Euclidean) 거리(거리측정): 두 관찰치 X와 Y사이의 직선거리

    -   $D(X,Y) = \sqrt{\sum_{i=1}^p(X_i-Y_i)^2}$

-   유클리디안 제곱거리(거리측정): 유클리디안 거리의 제곱

    -   $D(X,Y) = \sum_{i=1}^p(X_i-Y_i)^2$

-   코사인(cosine) 값 (유사성 측정): 두 관찰치 X와 Y 사이의 코사인 값

    -   $\begin{aligned} S(X,Y)=\frac{\sum_{i=1}^p X_i Y_i}{\sqrt{ \sum_{i=1}^p X_i^2 \cdot \sum_{i=1}^p Y_i^2}}\end{aligned}$

-   상관계수(유사성 측정): 두 관찰치 X와 Y 사이의 상관계수

    -   $\begin{aligned} S(X,Y)=\frac{\sum_{i=1}^p X_i Y_i}{\sqrt{ \sum_{i=1}^p (X_i-\bar{X})^2} \cdot \sqrt{\sum_{i=1}^p (Y_i-\bar{Y})^2}}\end{aligned}$

-   체비셰프(Chebyshev) 거리(거리측정) : 두 관찰치 X와 Y의 변수값 절대차이 중 최댓값

    -   D(X,Y) =

-   블록(block), 시티-블록(city-block), 또는 맨해튼(Manhattan)거리(거리측정) : 두 관찰치 X와 Y의 변수값 절대차이의 합

-   민코프스크(Minkowski) 거리 (거리측정)

-   커스텀(customized) 거리(거리측정)

-   변수 표준화 : 거리 혹은 유사성 측정방법들은 각 변수의 측정단위에 영향을 받음

    -   거리 또는 유사성의 측정에서 측정단위의 영향력을 없애기 위해서 군집분석에서는 각 변수들을 표준화하여 이용함.

    -   변수 W에 있어서 i번째 관찰치의 관측값을 $W_i, i = 1,2,…,N$ 이라고 하면 변수 W의 i번째 관측값을 표준화함.

        -   $Z_i = {W_i - \bar{W} \over S_w}$ (단, $i=1, 2, …, N$)\
            여기서 $\bar{W}={1\over N}\sum_{i=1}^N W_i$ : 변수 W의 평균

        -   $S_w=\sqrt{{1\over N-1}\sum_{i=1}^N (W_i - \bar{W})^2}$ : 분수 W의 표준편차

## 3. 계층적 군집분석

-   계층적 군집분석에서 관찰치의 군집화 과정은 각 관찰치들을 순차적으로 유사성의 순서를 이용하여 연결하는 과정으로 연결방법에는 다음과 같이 다섯 가지가 있음.

1.  최단연결법

2.  최장연결법

3.  중심연결법

4.  평균연결법

5.  와드의 방법(Ward's method)

    연결가능한 군집조합 중 연결된 후에 군집 내 제곱합을 계산하여 최소 제곱합을 가지게되는 군집끼리 연결 시키는 방법

-   덴드로그램(dendrogram): 계층적 군집분석 과정에서 관찰치들의 연결결과를 순서에 따라 정리해 놓은 그림을 말함

    -   이 덴드로그램에 의하여 계층적 군집분석방법의 결과를 이해할 수 있음.

    -   덴드로그램은 각 관찰치를 연결하는 가지들로 구성되어 있으며 관찰치들이 각 군집에 배정되는 순서를 볼 수 있도록 함.

    -   가지의 길이는 관찰치와 군집이 통합될 때의 거리측도 혹은 유사성측도와 비례

#### 고려사항

##### (1) 방법의 선택

-   각 군집분석방법의 특징

    -   최단연결법: 하나의 큰 군집화를 순차적으로 만들어가는 경향

    -   최장연결법: 비슷한 크기로 여러 개 군집을 만들어서 서로 연결시키는 경향

-   최단연결법은 최장연결법보다 더 적은 수의 군집을 찾게 됨. 반면 최장연결법은 군집의 개수는 많으나 한 군집 내의 크기가 더 작은 결과를 보임\
    대부분의 기타 방법들은 최단연결법의 특성과 최장연결법의 특징의 중간에 놓여 있다고 볼 수 있음.

-   여러 가지 계층적 군집분석방법 중에서 어느것이 더 유용하다고 말하기는 어렵고, 여러 군집방법을 수행해 보고 비교하는 것도 좋은 접근방법임.

##### (2) 군집분석 결과의 검증

-   계층적 군집분석방법에 의해서 군집을 구한 후, 결과의 타당성을 검증해 보는 것은 매우 중요한 습관임.

-   군집결과의 검증을 위해서는 묶인 군집들이 상식적으로 타당한 군집인지 다변량 그림 등을 그려서 확인할 수 있음.

    -   다변량그림의 예: ① 변수가 2개인 경우에 산점도, ② 주성분분석에서 구해진 상위 2개의 주성분을 이용한 산점도, ③ 변수가 3개인 경우에 3-차원 산점도 혹은 bubble 그림, ④ 주성분분석에서 구해진 상위 3개주성분을 이용한 3-차원 산점도 및 bubble 그림, ⑤ star 그림과 같은 다변량 그림(Andrews 그림과 Chernoff 얼굴그림도 가능) 등.

##### (3) 군집의 수 결정

-   계층적 군집분석에서 군집의 수를 결정하는 문제는 대부분 덴드로그램을 활용하는 방법을 사용. 덴드로그램에서 거리측도의 값이 큰 변화를 보이는 위치에서 군집의 수를 결정하는 방법임.

### 4. 비계층적 군집분석

-   계층적 군집분석방법 : 기본적으로 각 관찰치 사이의 유사성/거리 행렬을 구한 후에 관찰치들을 가까운 순서대로 연결해 나가는 방법임. 이 방법은 관찰치의 수가 많은 경우에는 관찰치들 사이의 유사성/거리 행렬을 구하는 것이 매우 방대하고, 오랜 시간이 소요됨.

-   관찰치의 수가 많은 경우 효율적인 방법이 비계층적 군집분석방법인 K-평균 군집분석

-   K-평균 군집분석 : 군집의 수를 미리 K개로 정한 후에 관찰치들을 K개의 군집으로 나누는 방법

-   K-평균 군집분석 절차

    1.  군집의 수 K를 정함
    2.  임의의 K개 관찰치를 K개 각 군집에 임의로 지정. 이를 K개 각 군집의 중심으로 이용
    3.  모든 관찰치를 군집중심으로부터 유클리디안 거리가 최소인 군집에 귀속
    4.  각 군집에 속한 관찰치들을 이용하여 군집중심을 새로 계산
    5.  변화(군집 간 관찰치 이동)가 없을 때까지 단계 3과 4를 반복

#### 고려사항

##### (1) 초깃값의 설정

-   K-평균 군집분석방법의 문제점은 군집화의 결과가 초깃값의 설정에 의존한다는 점임.

-   초깃값을 설정하는 대표적 방법은 데이터 내 임의의 K개 관찰치를 각 군집의 초깃값으로 설정하는 것임.

-   요즈음 많이 사용되는 방법은 계층적 군집분석을 만저 수행하여 구해진, 특히 와드( Ward)의 방법을 사용하여 계층적 군집분석을 수행한 후 중심점을 초깃값으로 사용한다면 매우 좋은 결과를 보인다고 알려져 있음.

-   데이터가 대용량이어서 계층적 군집분석을 사용해 초깃값을 구하기 어려운 경우에는 원 데이터로부터 적은 표본을 추출하여 계층적 군집분석을 수행한 후 초깃값을 구하기도 함.

##### (2) 군집의 수 결정

-   K-평균 군집분석에서 군집의 수를 결정하는 문제는 계층적 군집분석과 마찬가지로 정도는 없음.

-   먼저 2개의 군집에 대한 K-평균 군집분석을 수행하고, 그 다음으로 3개 군집에 대하여, 그리고 4개의 군집에 대한 K-평균 군집분석 등과 같이 군집의 수를 증가시키면서 K-평균 군집분석을 반복하여 수행한 후 이러한 결과 중 가장 좋은 결과를 보이는 군집의 수를 결정하는 방법.

-   또 다른 방법으로, 군집의 수행 이전에 주성분분석을 먼저 수행하고 상위 2개의 주성분을 이용하여 군집의 개수를 미리 그림으로 확인해 보는 방법도 있음.

-   마지막으로 계층적 군집분석을 먼저 수행하여 군집의 수를 덴드로그램을 통하여 미리 정한 후 비계층적 군집분석을 수행하는 방법도 사용

##### (3) 실용적 고려사항

-   K-평균 군집분석은 실무적으로 아주 활용도가 높은 군집분석방법임

    -   빠른 연산으로 인해 대규모의 데이터에도 손쉽게 군집분석 결과를 구할 수 있다는 장점이 있음.

-   K-평균 군집분석방법의 검증은 비계층적 군집분석방법과 마창가지로 그래프를 활용한 검증방법이 가능

### R - 군집분석 사례

#### (1) 계층적군집분석 실행하기

```{r}
beer = read.csv("./data/beerbrand.csv", header = T, row.names = 1)
head(beer)
summary(beer)
```

#### (2) 자료의 표준화

```{r}
zbeer = scale(beer)
round(apply(zbeer, 2, mean), 3)
round(apply(zbeer, 2, sd), 3)
```

#### (3) 거리행렬 계산하기

```{r}
zbeer_euc = dist(zbeer)
zbeer_euc[1]
zbeer_man = dist(zbeer, "manhattan")
zbeer_man[1]
```

#### (4) 계층적 군집분석 실행하기 - 최단연결법

```{r}
hc_s = hclust(zbeer_euc, method = "single")
hc_s
plot(hc_s, hang=-1)
```

#### (5) 계층적 군집분석 실행하기 - 최장연결법

```{r}
hc_c = hclust(zbeer_euc, method = "complete")
hc_c
plot(hc_c, hang = -1)
```

#### (6) 계층적 군집분석 실행하기 - 중심연결법

```{r}
hc_cen = hclust(zbeer_euc, method = "centroid")
hc_cen
plot(hc_cen, hang = -1)
```

#### (7) 계층적 군집분석 실행하기 - 와드의 방법

```{r}
hc_w = hclust(zbeer_euc, method = "ward.D")
hc_w
plot(hc_w, hang = -1)
```

#### (8) 소속 군집 확인

```{r}
hc_cen24 = cutree(hc_cen, 2:4)
hc_cen24
```

### R - K-평균 군집분석

#### (1) K-평균 군집분석 실행

```{r}
kmc = kmeans(zbeer, centers = 2)
kmc
```

#### (2) 소속 군집 산점도

```{r}
plot(zbeer, col=kmc$cluster, pch=16)
```

-   K-평균 군집 데이터의 모든 변수를 그리기위한 R 명령어

```{r}
pairs(zbeer, col=kmc$cluster, pch=16) 
# cex.labels = 1.5 사용하지 않는게 변수명이 더 크게 찍힌다.
```

```{r}
pairs(zbeer, col=kmc$cluster, pch=16, cex.labels = 1.5)
```

### 파이썬 - 계층적 군집분석

#### (1) 데이터 파일 읽기

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

beer = pd.read_csv("./data/beerbrand.csv", index_col="name")
beer.head()

beer.describe()

# 표준화 시행
from sklearn.preprocessing import StandardScaler
zbeer = StandardScaler().fit_transform(beer)
```

#### (2) 계층적 군집분석 - 최단연결법

```{python}
import scipy.cluster.hierarchy as sch

slink = sch.linkage(zbeer, 'single')
plt.figure(figsize=(12,7))
sch.dendrogram(slink, leaf_rotation=45, leaf_font_size=8, labels=beer.index)
plt.title("Dendrogram of Single linkage")
plt.show()
```

#### (3) 계층적 군집분석 - 와드연결법

```{python}
wlink = sch.linkage(zbeer, 'ward')
plt.figure().set_figwidth(12)
sch.dendrogram(wlink, leaf_rotation=45, leaf_font_size=8, labels=beer.index)
plt.title("Dendrogram of Ward's method")
plt.show()
```

#### (4) 계층적 군집분석 - 중심연결법

```{python}
clink = sch.linkage(zbeer, 'centroid')
plt.figure(figsize=(12,7))
sch.dendrogram(clink, leaf_font_size = 8, leaf_rotation=45, labels=beer.index)
plt.title("Dendrogram of Centroid linkage")
plt.show()
```

#### (5) 소속 군집 확인.

```{python}
from sklearn.cluster import AgglomerativeClustering

# 계층적군집방법 : ward 방법법
wcluster = AgglomerativeClustering(n_clusters=4, affinity='euclidean', linkage='ward')
member = wcluster.fit_predict(zbeer)
member

# 군집별 평균계산
member1 = pd.DataFrame(member, columns= ['cluster'], index=beer.index)
data_combinded = beer.join(member1)
data_combinded.groupby('cluster').mean()
```

#### (6) K-평균 군집분석

```{python}
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# 표준화
zbeer = StandardScaler().fit_transform(beer)

# 
kmc = KMeans(n_clusters=2)
kmc.fit(zbeer)

kmc.cluster_centers_

kmc.labels_


```

#### (7) 소속 군집 산점도

```{python}
plt.figure(figsize=(12,7))
plt.scatter(x=beer['calories'], y=beer['sodium'], c=kmc.labels_)
plt.show()
```
