---
title: "Multivariate Data Analysis - chapter 07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(python = reticulate::eng_python)
```

# 7장 판별분석

## 1. 판별분석 개요

-   판별분석\
    측정된 변수들을 이용하여 각 개체가 2개 이상의 그룹 중 어느 그룹에 속하는지를 판별하는 분석방법을 말함
-   판별분석이 이용되기 위해서는 각 개체는 여러개의 그룹 중에서 어느 그룹에 속해 있는지 알려져 있어야 하며, 소속그룹이 이미 알려진 케이스에 대하여 변수들을 측정하고 이들 변수를 이용하여 각 그룹을 가장 잘 구분할 수 있는 판별식을 만들어 분별하는 과정을 포함함.
-   판별분석이 이용되는 예
    -   `예` 어느 발굴현장에서 새로운 유물이 발견된 경우에 이 유물이 가능한 두 종족 중에 어느 종족의 유물인지를 판별하고자 하는 경우에 이용
    -   `예` 은행에서 과거자료를 이용하여 기업의 도산 여부를 판별할 수 있는 판별함수를 만든 다음 이를 이용하여 대상기업들을 판별하고자 하는데 이용

## 2. Fisher의 판별분석모형

### (1) Fisher의 판별함수

그룹의 수가 2개인 경우 판별함수

-   두 그룹을 $G_1, G_2$ 라 하고, 각각의 그룹에서 p개의 설명변수가 관측된 경우

-   이와 같이 집단의 수가 2개이고 p개의 설명변수가 있는 경우에 판별함수는 하나가 되며, 판별함수는 다음과 같이 표현됨

    $$
    \begin{aligned}
    Y &= b_1 X_1 + b_2 X_2 + ... + b_p X_p = b'X \\b' &= (b_1, b_2, ..., b_p) \\X &= (X_1, X_2, ..., X_p)
    \end{aligned}
    $$\
    이를 Fisher의 판별함수(Fisher's Discriminant Function)라고 함

### (2) Fisher의 판별함수 계수 추정

-   판별함수 계수 b를 구하는 방법

    -   판별함수 작성에서 기본 개념은 사전에 분류된 그룹들을 판별오류가 최소가 되도록 선형함수 작성

    -   다시 말해서 그룹 내 분산에 비해 상대적으로 그룹간 분산이 최대가 되도록 판별함수 작성

-   판별함수계수들의 벡터 **b**는 $$ 
      \lambda = {그룹 간 분산 \over 그룹 내 분산} 
      $$\
    이 최대가 되도록 하는 계수 **b**를 구함. 즉 두 집단 사이의 거리가 $\mu_{1Y}$ 와 $\mu_{2Y}$ 사이의 거리가 최대가 되도록 하는 **b**를 구함\
    \
    $b = \sum^{-1} (\mu_2 - \mu_1)$\
    $Y = b'X = (\mu_2 - \mu_1)'\sum^{-1} X$

### (3) Fisher의 판별함수를 이용한 분류

-   판별함수 : $Y=0.545X_1 - 0.558X_2 - 0.24X_3$

    -   각 집단의 판별함수값의 평균: $\bar{Y}_1 = -33.515, \bar{Y}_2 = -29.529$

    -   분류기준값 : $Y_c = {(-33.515)+(-29.529) \over 2} = -31.522$

    -   첫 번째 케이스의 경우에 판별 점수

        -   $Y_1=0.545 X_1 - 0.558 X_2 - 1.024 X_3$\
            $= 0.545 \times 98 - 0.558 \times 81 - 1.024 \times 38$  \
            $= -30.749$

    -   $Y_1 > Y_c$ 이므로 그룹 2로 분류됨

## 3. 선형판별분석(Linear Discriminant Analysis, LDA)

-   두 그룹인 경우 $X_{G1}$ 과 $X_{G2}$ 는 각각 다변량 정규분포를 따른다고 가정\
    $X_{G1} = N(\mu_1, \Sigma_1)$\
    $X_{G2} = N(\mu_2, \Sigma_2)$

<!-- -->

-   베이지안 규칙(Bayesian rule)을 이용한 분류방법\
    $P(G_2|X=x) > P(G_1|X=x)$ 이면 그룹 $G_2$ 로 분류

-   베이지안 최적해

    -   어떤 기준 T에 대해서, 다음과 같으면 그룹 $G_2$ 로 분류

$(x-mu_1)^T\Sigma_1^{-1}(x-\mu_1) + \ln|\Sigma_1|-(x-\mu_2)^T\Sigma_2^{-1}(x-\mu_2)-\ln|\Sigma_2|>T$

-   두 그룹의 분산이 같다고 가정하면, $b'x>c$ 이면 그룹 $G_2$ 로 분류

## 4. 판별함수모형 평가

-   람다(Wilk's lambda) 통계량 : $A = {|W| \over |T|}$

    -   W : within-groups sum of square matrix,\
        T : total sum of square matrix

    -   이 값이 0에 가까울 수록 좋고, 1에 가까울 수록 나쁘다는 것을 의미함

    -   분류표(confusion matrix) 이용

## 5. 판별변수 선택

-   판별력이 높은 변수 선택

-   R에서는 klaR::greedy.wilks() 함수 이용

## 6. 판별분석 과정

-   각 관찰값으로부터 집단구분과 여러개의 설명변수들을 측정

-   관찰값이 어느 집단에 속하는지 판별하는 데 도움이 되는 변수들을 설명변수들에서 선택

-   선택된 변수를 이용하여 판별함수를 만들어 집단들을 구분하는 기준을 마련

-   판별함수를 이용하여 집단들이 얼마나 정확하게 구분되는지 파악

-   어느 집단에 속하는지를 알 수 없는 새로운 관측치로부터 구한 설명변수 값을 이용하여 이 관측값이 어느 집단에 속하는지 판별

## 7. R을 이용한 선형판별분석

### (1) 선형판별분석 실행하기

```{r}
alcohol = read.csv("./data/alcohol.csv")
library(MASS)
alcohol_lda=lda(TYPE~., data=alcohol)
alcohol_lda
```

-   "Prior prob..."" 각 그룹별 변수에 비례한 사전 확률값

-   그룹의 수가 3개이므로 2개의 선형판별함수가 출력됨

### (2) 분류하기

```{r}
pred_lda = predict(alcohol_lda, newdata=alcohol)
names(pred_lda)
head(pred_lda$class)
head(pred_lda$posterior)
head(pred_lda$x)
```

-   predict() 함수: 구해진 판별함수를 이용하여 임의의 데이터를 분류

-   각 케이스는 사후확률값(pred.lda\$posterior)이 큰 그룹으로 분류됨

-   "pred.lda\$x" 각 케이스의 두 판별점수를 보여줌

### (3) 분류표 및 오분류율

```{r}
indep_vars = alcohol[,-1]
alcohol_man = manova(as.matrix(indep_vars)~pred_lda$class)
alcohol_wilks = summary(alcohol_man, test="Wilks")
alcohol_wilks

confm_lda = table(alcohol$TYPE, pred_lda$class)
confm_lda

# error rate
error = 1 - sum(diag(confm_lda))/sum(confm_lda)
error
```

-   Wilks = 0.067655이고, p-값은 $2.2e-16 = 2.2 \times 10^{-16}$ 보다 작으므로 판별모형이 유의

    -   오분류율 = (6+9)/(18+23+21+6+9) = 15/77 = 0.195

### (4) 변수 선택하기

```{r}
library(klaR)
alcohol_forward = greedy.wilks(TYPE~., data=alcohol, noveau=0.01)
alcohol_forward

```

-   유의확률 기준이 0.01인 경우, 선택된 변수는 "BU1", "MEPR", "MEOH", "ACET", "LNPR01"

### (5) 변수 선택 후 판별분석 실행하기

```{r}
alcohol_fwd_lda = lda(alcohol_forward$formula, data = alcohol)
alcohol_fwd_lda
```

### (6) 판별함수 분류결가 산점도

```{r}
library(dplyr)
alcohol$TYPE = recode(alcohol$TYPE, typeA="A", typeB = "B", typeC = "C")
pred_alc = predict(alcohol_fwd_lda, newdata=alcohol)

#판별함수 산점도
plot(pred_alc$x[,1], pred_alc$x[,2], pch=19)
text(pred_alc$x[,1], pred_alc$x[,2], alcohol$TYPE, cex=0.7, pos=4, col="red")
abline(v=-2, lty=2)
lines(c(-2,3.7), c(-0.1, -0.1), lty=2)
      
```

## 8. 파이썬을 이용한 선형 판별분석

```{python}
import numpy as np
import pandas as pd

# read data
alcohol = pd.read_csv("./data/alcohol.csv")

# 변수 선택
X = alcohol.iloc[:, 1:]
Y = alcohol["TYPE"]

# 선형판별분석 실행
from sklearn.discriminant_analysis  import LinearDiscriminantAnalysis
clf = LinearDiscriminantAnalysis()
clf.fit(X,Y)
clf.fit_transform(X, Y)

# 분류하기
pred_class = clf.predict(X)
pred_class

# 사후확률(posterior prob) 구하기
pred_posterior = clf.predict_proba(X)
pred_posterior

# 분류표 구하기
from sklearn.metrics import confusion_matrix
confusion_matrix(Y, pred_class)

# 오분류율 구하기
from sklearn.metrics import accuracy_score
print('Accurary = ' + str(accuracy_score(Y, pred_class)))
Accurary = 0.8051948051948052




```
