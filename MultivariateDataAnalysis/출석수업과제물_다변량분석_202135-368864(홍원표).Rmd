---
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
<font color='blue' size = 5>
출석수업 과제물(평가결과물) 표지(온라인제출용)
</font>

### 교과목명 : 다변량분석
### 학 번 : 202135-368864
### 성 명 : 홍 원 표
### 강 의 실 : 서울(5월14일 Zoom) 지역대학 호 
### 연 락 처 : 010-5343-4341
___________________________________________________________________________

## 1-4

### (1)
```{r}
# 산점도 행렬
pairs(longley)
# 별그림
stars(longley)
# 얼굴그림 : install.packages("aplpack")
library(aplpack)
faces(longley)
```
- 산점도 행렬을 보면 GNP.deflator, GNP, Population, Year, Employed 변수끼리의 상관관계가 뚜렷하게 보나타납니다.  
  연도(Year)에 따라 인구(Population) 변수의 상관관계가 가장 뚜렷해 보이고 소득관련(GNP, GNP.deflator) 변수도 상관관계도 높아 보입니다.  
  하지만 실업자(Unemployed) 수와 군인(Armed.Forces) 변수는 상관관계가 약해보입니다.

- 별그림을 보면 대부분의 변수들이 연도에 따라 증가된것으로 보여지고 1951년에 군인(Armed.Forces)이 많이 들어났고, 1958년도에는 실업자(Unemployed) 수가 많이 늘어난것으로 벼여집니다. 전반적으로 군인과 실업자 수를 제외하고는 연도가 증가함에 따라 모두 같이 증가한것으로 보여집니다.

- 얼굴그림은 연도별로 출력된 내용으로는 특정 변수가 어떤 변화가 있었는지 파악이 어려울것 같고 연도가 증가함에 따라 전반적으로 얼굴의 모양이 좋아지는 것을 봐서 모든 변수들의 항목이 좋아진 것으로 보여집니다.

### (2)
```{r}
# longley 데이터를 longley_0514.csv로 저장
write.csv(longley, "./exdata/longley_0514.csv")
```

### (3)
```{python}
# python block
import pandas as pd
# 첫행을 컬럼명으로, 첫열을 row 이름으로 사용하여 csv 파일 읽기기
longley = pd.read_csv("./exdata/longley_0514.csv", header = 0, index_col=0)
longley.head()

# 산점도 행렬(seaborn 사용)
import seaborn as sns
sns.pairplot(longley)
```

- R에서의 산점도 행렬은 단색으로 그려지고 변수명은 해당 변수의 행렬이 일치하는 곳에 출력하지만 파이썬에서는 왼쪽과 아래에 변수명이 출력됩니다. 그리고 변수명의 행렬이 일치하는 곳에는 히스토그램이 출력되고 산점도와 히스토그램 색상이 파란색으로 출력이 됩니다.
- 파이썬에서도 변수들 간의 산점도는 R과 동일한 분포로 출력되고 있습니다.

---  

---  

## 2-4

### (1) R을 이용한 주성분분석

#### ① 자료읽기 및 요약통계량
```{r}
# 자료읽기 - 처음 줄은 열 이름, "state" 열은 행 이름
ex2_4 = read.csv("./data/ex2-4.csv", header = T, row.names = "state")
head(ex2_4)
# 자료의 요약정보보
summary(ex2_4)
```

```{r eval=FALSE, include=FALSE}
##### ② 상관계수행렬 및 산점도행렬 보기
# 상관계수 출력 - 소수점 이하 2자리 표시
round(cor(ex2_4), 2)
# 산점도 표시
plot(ex2_4, pch=19)
```

- 살인(Murder)와 폭행(Assault)은 양의 상관관계가 높고, 도시인구비율(UrbanPop)은 다른 변수들과의 낮은 상관관계로 보아 도시인구 비율과 관련없이 살인, 폭행, 강간이 발생하는 것으로 보여집니다.  
- 강간(Rape)은 살인(Murder)과 어느정도 관계가 있어 보입니다.

#### ③ 주성분분석 실행하기
```{r}
# 주성분분석 - 공분산행렬 이용(cor=F), 각 케이스의 주성분점수 포함(score=T)
(ex2_4_pca = princomp(ex2_4, cor=F, score=T))
# 주성분분석 요약정보
summary(ex2_4_pca)
```

- 주성분분석 결과를 summary() 함수를 이용해 보면 첫번째 주성분이 96.55% 설명력을 가지는 것을 알 수 있습니다.

#### ④ 스크리 그림 및 주성분 계수
```{r}
par(mfrow=c(1,2))
# 스크리 그림 그리기
screeplot(ex2_4_pca, type='lines', pch=19, main='Scree plot')
# 누적분산 그리기
ex2_4_var = ex2_4_pca$sdev^2
ex2_4_var_ratio = ex2_4_var / sum(ex2_4_var)
plot(cumsum(ex2_4_var_ratio), type='b', pch=19, xlab='Component', ylab='Cumulative Proporation', main="Variance Explained")
# loadings 표시 - 소수점 이하 3자리 반올림 표시
round(ex2_4_pca$loadings[, c(1)], 3)
```
```{r eval=FALSE, include=FALSE}
# 행렬도
biplot(ex2_4_pca, cex=0.7, col=c('red', 'blue'))
title('Biplot')
```

- 스크리 그림에서 유효한 주성분은 1개로 판단됩니다.  
  하나의 주성분의 계수는 다음과 같습니다.
  - $PC_1 = 0.042 \times Murder + 0.995 \times Assault + 0.046 \times UrbanPop + 0.075 \times Rape$  

---

### (2) 파이썬을 이용한 주성분 분석

#### ①  자료 읽기  및 기술통계량

```{python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# 자료읽기
ex2_4 = pd.read_csv("./exdata/ex2-4.csv", header = 0, index_col = 0)
ex2_4.head()
```

```{python}
# 변수이름 확인하기
ex2_4.columns
```

```{python}
# 기술통계량 구하기 - 소수점 이하 2자리 반올림 표시
round(ex2_4.describe(), 2)
```


#### ② 상관계수행렬 및 산점도행렬 보기
```{python}
# 상관계수 행렬
ex2_4.corr()
```


```{python}
# 산점도 행렬(seaborn 사용)
import seaborn as sns
sns.pairplot(ex2_4)
```

#### ③ 주성분분석 실행하기
```{python}
from sklearn.decomposition import PCA
# 주성분분석 - 주성분 수를 3으로 함.
pca = PCA(n_components=4)
pca_ex2_4 = pca.fit_transform(ex2_4)

# 주성분 분산
pca.explained_variance_
```

```{python}
# 주성분 표준편차
np.sqrt(pca.explained_variance_)
```
- 주성분 표준편차를 R과 비교해보면 파이썬에서 더 큰값으로 구해진 것을 볼 수 있습니다.
```{python}
# 주성분분산비율
pca.explained_variance_ratio_
```
- R에서의 주성분의 분산비는 거의 비슷한 값으로 보여지기 때문에 전반적으로 R보다 파이썬에서 분산이 더 크게 구해진다는 것을 알 수 있습니다. 
- 하지만 동일하게 첫번째 주성분이 96.55%의 설명력을 가지는 것을 알 수 있습니다.

#### ④ 스크리 그림 및 주성분 계수

```{python}
# 이전의 화면을 지운다.
plt.clf()
```


```{python}
plt.figure()

# 화면분할 1행 2열에서 첫번째
plt.subplot(121)
plt.scatter(range(1,pca.n_components_+1), pca.explained_variance_ )
plt.plot(range(1,pca.n_components_+1), pca.explained_variance_)
plt.title('Scree plot')
plt.xlabel('Number of components')
plt.ylabel('Variances')
plt.grid()

# 화면분할 2행 2열에서 2번째
plt.subplot(122)
plt.scatter(range(1,pca.n_components_+1), np.cumsum(pca.explained_variance_ratio_))
plt.plot(range(1,pca.n_components_+1), np.cumsum(pca.explained_variance_ratio_))
plt.title('Variance Explained')
plt.xlabel('Number of components')
plt.ylabel('Cumulative Proporation')
plt.grid()
# 그래프의 위치 조정
plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25, wspace=0.35)
plt.show()


```

```{python}
# 주성분계수 - 소숫점 이하 3자리 표시
np.round(pca.components_[0,], 3)
```

- 파이썬으로 출력한 스크리 그림에서도 유효한 주성분은 1개로 판단됩니다.  
  하나의 주성분의 계수는 다음과 같이 R에서 구한것과 동일합니다.
  - $PC_1 = 0.042 \times Murder + 0.995 \times Assault + 0.046 \times UrbanPop + 0.075 \times Rape$  
  
---   

---   



## 4-5 R분석

### 공통 자료 읽기
```{r}
#customerID 는 row.name으로 사용하고 첫번째 행은 열이름으로 사용
mall = read.csv("./exdata/mall_customer.csv", header = T, row.names = 1)
head(mall)
```
### 남성그룹 데이터 분석
```{r}
# Gender가 "Male"인 데이터만 추출하여 분석
mallm = mall[mall$Gender=="Male",2:4]
head(mallm)
summary(mallm)
```

#### (1)  
```{r}
# 변수 표준화
zmallm = scale(mallm, center = T, scale = T)
head(zmallm)
```




#### (2)
```{r}
# 유클리디안 거리 구하기
zmallm_euc = dist(zmallm, method = "euclidean")
# 와드의 방법으로 군집화
hcm_w = hclust(zmallm_euc, method = "ward.D")
# Dendrogram 출력
plot(hcm_w)
abline(h=12, lty=3, col="red")
```


- 와드방법으로 군집화 후 height를 보면 12보다 작은 경우에 SSE값이 급격한 변화가 있는 것으로 보여지기 때문에 4개의 군집으로 분리하는게 적절하다고  판단됨.


#### (3) 
```{r}
# 최장연결법으로 군집화
hcm_c = hclust(zmallm_euc, method = "complete")
# 덴드로그램 출력
plot(hcm_c, hang=-1)
abline(h=2.9, lty=3, col="red")
```


- 최장거리 방법으로 군집화 후 height를 보면 2.9보다 작은 경우에 SSE값이 급격한 변화가 있는 것으로 보여지기 때문에 6개의 군집으로 분리하는게 적절하다고  판단됨.

#### (4) 

- 와드의 방법으로 군집화한 덴드로그램을 보면 Height가 좀 더 낮은 비율에서 군집이 더 많이 나눠지는 것으로 보여지고 최장연결법으로 군집화한 덴드로그램에서는 Height가 중심부분 부터 군집이 더 빠르게 나눠지는 것으로 보여진다.

#### (5)

```{r}
# K-Means 군집화화
kmcm = kmeans(zmallm, centers = 6)
kmcm
```

```{r}
# 소속 군집 산점도
plot(zmallm, col=kmcm$cluster, pch=16)

```

- K-평군 군집분석으로 처음 2개의 변수인 Age와 Income으로 생성된 군집 데이터 그림으로 'kmcm$cluster' 는 군집의 번호를 의미한다. 
- pch=16은 산점도의 점을 색상으로 채우는 옵션이다.

```{r}
# K-평균 군집 데이터의 모든 변수에 대한 산점도 행렬을 그려본다.
pairs(zmallm, col=kmcm$cluster, pch=16, cex.labels = 1.5)
```

- cex.labels = 1.5는 산점도의 대각선에 출력될 변수명의 크기를 조절한다.
- Income의 상단의 그래프를 보면 나이가 많아 질수록 수입은 수입이 일정하게 줄어드는것을 볼 수 있다.
- 나이가 평균이하에서 소비점수도 높게 나타나는 경우도 많아짐을 알 수 있다.

### 여성그룹 데이터 분석


```{r}
# Gender가 "Female"인 데이터만 추출하여 분석
mallf = mall[mall$Gender=="Female",2:4]
head(mallf)
summary(mallf)
```

#### (1)  
```{r}
# 변수 표준화 : 0-1 변환을을 이용
maxX = apply(mallf, 2, max)
minX = apply(mallf, 2, min)
z01mallf=scale(mallf, center=minX, scale=maxX - minX)
summary(z01mallf)
```




#### (2)
```{r}
# 유클리디안 거리 구하기
zmallf_euc = dist(z01mallf, method = "euclidean")
# 와드의 방법으로 군집화
hcf_w = hclust(zmallf_euc, method = "ward.D")
# Dendrogram 출력
plot(hcf_w)
abline(h=2.1, lty=3, col="red")
```

- 와드방법으로 군집화 후 Height를 보면 2.1보다 작은 경우에 SSE값이 급격한 변화가 있는 것으로 보여지기 때문에 6개의 군집으로 분리하는게 적절하다고  판단됨.


#### (3) 
```{r}
# 최장연결법으로 군집화
hcf_c = hclust(zmallf_euc, method = "complete")
# 덴드로그램 출력
plot(hcf_c, hang=-1)
abline(h=0.6, lty=3, col="red")
```

- 최장거리 방법으로 군집화 후 height를 보면 0.6보다 작은 경우에 SSE값이 급격한 변화가 있는 것으로 보여지기 때문에 7개의 군집으로 분리하는게 적절하다고  판단됨.

#### (4) 

- 와드의 방법으로 군집화한 덴드로그램을 보면 Height가 좀 더 낮은 비율에서 군집이 더 많이 나눠지는 것으로 보여지고 최장연결법으로 군집화한 덴드로그램에서는 Height가 중심부분 부터 군집이 더 빠르게 나눠지는 것으로 보여진다.

#### (5)

```{r}
# K-Means 군집화화
kmcf = kmeans(z01mallf, centers = 6)
kmcf
```

```{r}
# 소속 군집 산점도
plot(z01mallf, col=kmcf$cluster, pch=16)

```

- K-평군 군집분석으로 처음 2개의 변수인 Age와 Income으로 생성된 군집 데이터 그림으로 'kmcf$cluster' 는 군집의 번호를 의미한다. 
- pch=16은 산점도의 점을 색상으로 채우는 옵션이다.

```{r}
# K-평균 군집 데이터의 모든 변수에 대한 산점도 행렬을 그려본다.
pairs(z01mallf, col=kmcf$cluster, pch=16, cex.labels = 1.5)
```

- cex.labels = 1.5는 산점도의 대각선에 출력될 변수명의 크기를 조절한다.


## 4-5 Python 분석

### 공통 자료 읽기
```{python}
# 주요 패키지 로드
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# 데이터 읽기
mall = pd.read_csv("./exdata/mall_customer.csv", header=0, index_col = "CustomerID")
mall.head
```

### 남성그룹 데이터 분석

```{python}
# 테이블에서 남성의 데이터 행으로만 구성되고 "Age", "Income", "Spending_Score" 열로 구성된 데이터 추출
Mallm = mall[mall['Gender'] == 'Male'][["Age", "Income", "Spending_Score"]]
```

#### (1) 
```{python}
# 데이터 표준화 패키지 로드
from sklearn.preprocessing import StandardScaler
# 표준화 실행
zMallm = StandardScaler().fit_transform(Mallm)
```

#### (2) 
```{python echo=TRUE}
# 군집분석 패키지 불러오기
import scipy.cluster.hierarchy as sch
wMallmlink = sch.linkage(zMallm, 'ward')

plt.figure(figsize=(7,5))
dend = sch.dendrogram(wMallmlink, leaf_rotation=80, leaf_font_size=10, labels=Mallm.index)
plt.title("Dendrogram of Ward's linkage")
# 덴드로그램에 라인 그리기기
ax = plt.gca() 
bounds = ax.get_xbound() 
ax.plot(bounds, [6, 6], '--', c='r')
plt.show()

```

- 와드방법으로 군집화 후 height를 보면 6보다 작은 경우에 SSE값이 급격한 변화가 있는 것으로 보여지기 때문에 4개의 군집으로 분리하는게 적절하다고  판단됩니다.

#### (3)
```{python}
sMallmlink=sch.linkage(zMallm, 'complete')
plt.figure(figsize=(7,5))
dend=sch.dendrogram(sMallmlink, leaf_rotation=80, leaf_font_size=10, labels=Mallm.index)
plt.title("Dendrogram of Complete linkage")
ax = plt.gca() 
bounds = ax.get_xbound() 
ax.plot(bounds, [3, 3], '--', c='k')
plt.show() 
```


- 최장거리 방법으로 군집화 후 height를 보면 3보다 작은 경우에 SSE값이 급격한 변화가 있는 것으로 보여지기 때문에 6개의 군집으로 분리하는게 적절하다고  판단됩니다.

#### (4)

- 와드의 방법으로 군집화한 덴드로그램을 보면 Height가 좀 더 낮은 비율에서 군집이 더 많이 나눠지는 것으로 보여지고 최장연결법으로 군집화한 덴드로그램에서는 Height가 중심부분 부터 군집이 더 빠르게 나눠지는 것으로 보여진다.


#### (5) 

```{python}
from sklearn.cluster import KMeans
# K-means 군집분석
kmc = KMeans(n_clusters=6)
kmc.fit(zMallm)
# 군집중심알기
kmc.cluster_centers_
# 소속 군집 알기
kmc.labels_
# 첫번째 변수와 2번째 변수로 소속 군집 산점도를 그려본다.
plt.figure(figsize=(5,5))
plt.scatter(Mallm["Age"], Mallm["Income"], c=kmc.labels_)
plt.show()
```


### 여성그룹 데이터 분석
```{python}
# 테이블에서 여성의 데이터 행으로만 구성되고 "Age", "Income", "Spending_Score" 열로 구성된 데이터 추출
Mallf = mall[mall['Gender'] == 'Female'][["Age", "Income", "Spending_Score"]]
```

#### (1) 
```{python}
# 데이터 표준화 패키지 로드
from sklearn.preprocessing import StandardScaler
# 표준화 실행
zMallf = StandardScaler().fit_transform(Mallf)
```

#### (2) 
```{python echo=TRUE}
# 군집분석 패키지 불러오기
import scipy.cluster.hierarchy as sch
wMallflink = sch.linkage(zMallf, 'ward')

plt.figure(figsize=(7,5))
dend = sch.dendrogram(wMallflink, leaf_rotation=80, leaf_font_size=10, labels=Mallf.index)
plt.title("Dendrogram of Ward's linkage")
# 덴드로그램에 라인 그리기기
ax = plt.gca() 
bounds = ax.get_xbound() 
ax.plot(bounds, [5, 5], '--', c='r')
plt.show()

```

- 와드방법으로 군집화 후 height를 보면 4보다 작은 경우에 SSE값이 급격한 변화가 있는 것으로 보여지기 때문에 6개의 군집으로 분리하는게 적절하다고  판단됩니다.

#### (3)
```{python}
sMallflink=sch.linkage(zMallf, 'complete')
plt.figure(figsize=(7,5))
dend=sch.dendrogram(sMallflink, leaf_rotation=80, leaf_font_size=10, labels=Mallf.index)
plt.title("Dendrogram of Complete linkage")
ax = plt.gca() 
bounds = ax.get_xbound() 
ax.plot(bounds, [3.7, 3.7], '--', c='k')
ax.text(bounds[1], 3.7, '5', va='center', fontdict={'size': 15})
ax.plot(bounds, [2.5, 2.5], '--', c='k')
ax.text(bounds[1], 2.5, '7', va='center', fontdict={'size': 15})


plt.show() 
```


- 최장거리 방법으로 군집화하여 덴드로그램을 보면 2.5에서 7개의 군집으로 분리하는게 좋을지 4.7에서 5개의 군집으로 분리해야할지 모르겠지만 덴드로 그램의 색상을 보면 5개의 군집으로 분리하는게 더 좋아 보이는것 같다.

#### (4)

- 와드의 방법으로 군집화한 덴드로그램을 보면 Height가 좀 더 낮은 비율에서 군집이 더 많이 나눠지는 것으로 보여지고 최장연결법으로 군집화한 덴드로그램에서는 Height가 중심부분 부터 군집이 더 빠르게 나눠지는 것으로 보여진다.


#### (5) 

```{python}
from sklearn.cluster import KMeans
# K-means 군집분석
kmc = KMeans(n_clusters=6)
kmc.fit(zMallf)

# 군집중심알기
kmc.cluster_centers_
# 소속 군집 알기
kmc.labels_
# 첫번째 변수와 2번째 변수로 소속 군집 산점도를 그려본다.
plt.figure(figsize=(5,5))
plt.scatter(Mallf["Age"], Mallf["Income"], c=kmc.labels_)
plt.show()
```

---

이 문서는 RStudio에서 R script와 Python script를 포함한 R markdown 문서로 생성하였습니다.

---

<center> <font color="blue" size=3>-- 2023년 05월 14일 다변량분석 출석수업 과제물 끝 --</font> </center>