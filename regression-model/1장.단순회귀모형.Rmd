
---
title: "단순회귀모형(simple regression models)"
output: html_document
---

## 회귀분석(regression analysis)
독립변수(independent variable, 설명변수:explanatory variable)들과 종속변수(dependent variable, 반응변수:response variable)간의 함수관계를 규명하는 통계적인 분석방법

## 단순회귀모형(simple regression models)
모형이 회귀계수로 볼 때도 선형(linear in the regression coefficient)이고, 독립변수(설명변수)로 볼 때도 선형(linear in the independent variable)이며, 독립변수가 하나뿐이므로 단순회귀모형이라고 한다.
$$Y_i=\beta_0 + \beta_1X_i + \epsilon_i$$
$Y_i$는 상수항($\beta_0 + \beta_1X_i$)과 오차항($\epsilon_i$)으로 구성되어 있다.\

1. $Y_i$는 i번째 측정된 Y값으로 확률변수이다.\
2. 오차항의 평균 $E(\epsilon_i)=0$이므로, \
$E(Y_i)=E(\beta_0+\beta_1X_i+\epsilon_i) = \beta_0+\beta_iXi + E(\epsilon_i) = \beta_0+\beta_1X_i$이다.\
$\beta_0+\beta_1X_i$은 상수항이기 때문에 $E(\beta_0+\beta_1X_i)=\beta_0+\beta_1X_i$가 된다.\
주어진 $X$에서 $Y$의 기대값을 $\mu_{Y.X}=\beta_0+\beta_1X$라고하면 $Y=\mu_{Y.X}+\epsilon$으로 표현한다.\
3. 오차항$\epsilon_i$의 분산은 등분산(homoscedastic)$\sigma^2$으로 가정한다. 따라서 반응변수 $Y_i$의 분산은 $Var(Yi)=Var(\beta_0+\beta_1X_i+\epsilon_i) = Var(\epsilon_i)=\sigma^2$ 이므로, 반응변수 $Y_i$도 등분산 $\sigma^2$을 갖는다.\
4. 반응변수 $Y$의 오차항들은 서로 독립이라고 가정한다. 두 변수 간의 공분산(covariance) $Cov(\epsilon_i, \epsilon_j)=0, i \neq j$이 성립되는 가정이다. 오차항 $\epsilon_i$와 $\epsilon_j$가 서로 독립이므로, 반응변수 $Y_i$와 $Y_j$도 서로 독립이다.

**단순회귀모형의 대체모형(alternative model)**\
$$\begin{matrix}
Y_i&=&\beta_0+\beta_1X_i+\epsilon_i\\
&=&(\beta_0 + \beta_1\bar{X})+\beta_1(X_i-\bar{X}) + \epsilon_i\\
&=&\beta_0^*+\beta_1(X_i-\bar{X})+\epsilon_i
\end{matrix}$$
$\beta_1\bar{X}$를 더하고 빼줘서 계산하고 $\beta_0^*$는 $\beta_0+\beta_1\bar{X}$를 대체하여 상수항으로 대체체한것이다.\
이 모형은 설명변수로서 $X_i$대신에 ($X_i-\bar{X}$)를 사용하는 경우이다.


## 회귀선의 추정

**최소제곱법(method of least squares)**\
표본자료(sample data) $(X_1,Y_1), (X_2,Y_2), ..., (X_n, Y_n)$ 로부터 추정하여 얻은 직선을 $\hat{Y}=b_0+b_1X$라고 하자. \
이와같은 직선을 추정된 회귀직선, 또는 간단히 **회귀선**이라고 한다.\
최소제곱법은 $Y_i=\beta_0+\beta_1X_i+\epsilon_i$에서 오차제곱들의 합$[S=\sum_{i=1}^n(Y_i-\beta_0-\beta_1X_i)^2]$을  최소로하는 $\beta_0$와 $\beta_1$의 값들을 이들의 추정값 $b_0$와 $b_1$으로 하는 방법이다. 이를 구하기 위해서는 오차제곱합 S를 $\beta_0$와 $\beta_1$으로 각각 편미분하여 이를 0으로 하여 구하면 된다.\
**$\beta_0$로 편미분하는 방법** \
$S=\sum_{i=1}^n(Y_i-\beta_0-\beta_1X_i)^2$ 전체를 미분하여
$\sum_{i=1}^n2(Y_i=\beta_0-\beta_1X_i)$에 다시 $Y_i-\beta_0-\beta_1X_i$를 $\beta_0$로 미분하여 곱한다.\
$Y_i-\beta_0-\beta_1X_i$를 $\beta_0$로 미분하면 $-1$이 된다.\
따라서 $\sum_{i=1}^n2(Y_i-\beta_0-\beta_1X_i)(-1) = -2\sum_{i=1}^n(Y_i-\beta_0-\beta_1X_i)$

**$\beta_1$도 같은 방법으로 편미분 한다.** \
$S=\sum_{i=1}^n(Y_i-\beta_0-\beta_1X_i)^2$ 전체를 미분하여
$\sum_{i=1}^n2(Y_i-\beta_0-\beta_1X_i)$에 다시 $Y_i-\beta_0-\beta_1X_i$를 $\beta_1$로 미분하여 곱한다.\
$Y_i-\beta_0-\beta_1X_i$를 $\beta_1$로 미분하면 $-X_i$가 된다.\
따라서 $\sum_{i=1}^n2(Y_i-\beta_0-\beta_1X_i)(-X_i) = -2\sum_{i=1}^nX_i(Y_i-\beta_0-\beta_1X_i)$\
두 수식의 $\beta_0$과 $\beta_1$을 $b_0$와 $b_1$으로 대체하여 수식을 정리하면 \
$\sum Y_i = nb_0 + \sum b_1X_i$\
$\sum X_iY_i = b_0\sum X_i + b_1 \sum X_i^2$\
\
\

첫번째 수식을 $b_0$로 정리하면 \ \
$b_0 = \bar{Y} - b_1\bar{X}$가 된다.


**정리방법** \
$n b_0 = \sum Y_i - b_1 \sum X_i$ \ \
$b_0 = \frac{\sum Y_i}{n} - b_1\frac{\sum X_i}{n}$ \
여기서, $\frac{\sum Y_i}{n} = \bar{Y}$, $\frac{\sum X_i}{n} = \bar{X}$이므로 \ \ 
$b_0 = \bar{Y} - b_1\bar{X}$\
\
\

$b_0$을 두번째 수식에 대입하여 $b_1$로 정리하면\ \
$b_1=\frac{\sum(X_i-\bar{X})(Y_i-\bar{Y})}{\sum(X_i-\bar{X})^2}$가 된다.\
\

**정리방법** \
$\sum X_iY_i = (\bar{Y} \sum X_i - b_1\bar{X} \sum X_i) + b_1 \sum X_i^2$\ 
\
$b_1 \sum X_i(X_i - \bar{X})= \sum X_i(Y_i - \bar{Y})$\
\
$b_1 = \frac{\sum X_i(Y_i - \bar{Y})}{\sum X_i(X_i - \bar{X})}$\
\
분자에 $\bar{X}\sum (Y_i - \bar{Y})$를 더해주고 정리를 하면 
$\sum (X_i-\bar{X})(Y_i - \bar{Y})$가되고\
\
분모에 $\bar{X}\sum (X_i - \bar{X})$를 더해주고 정리를 하면 
$\sum (X_i-\bar{X})^2$가된다.\
\
각각 더해준 $\bar{X}\sum (Y_i - \bar{Y})$와 $\bar{X}\sum (X_i - \bar{X})$는 모두 0이다.\

$\sum (Y_i - \bar{Y}) = \sum Y_i - n\times \bar{Y} = 0$, 총합 - 평균 * n = 0






간단 표현식\
$S_{XX}=\sum(X_i-\bar{X})^2,\\ S_{YY}=\sum(Y_i-\bar{Y})^2,\\ S_{XY}=\sum(X_i-\bar{X})(Y_i-\bar{Y})$
\
\
절편 $b_0$와 기울기 $b_1$의 추정식\
$b_1 = \frac{S_{XY}}{S_{XX}}=\frac{\sum(X_i-\bar{X})(Y_i-\bar{Y})}{\sum(X_i-\bar{X})^2}$\
\
$b_0 = \bar{Y} - b_1\bar{X}$
\
이와같이 얻어진 $\beta_0$와 $\beta_1$의 추정량 $b_0$와 $b_1$을 **최소제공추정량(least squares estimator)**이라고 부른다.\
$\hat{Y} - \bar{Y} = b_1(X_i-\bar{X})$로 표현할 수 있다.\


**분산분석표를 이용한 추정된 회귀식 구하기**
```{r}
market = read.table("./data/market-1.txt", header = T)
head(market)
# Y를 반응변수로 X를 설명변수로 놓고 선형모델을 구한다(linear model)
market.lm = lm(Y~X, data=market)
summary(market.lm)
```

추정된 회귀식은 $\hat{Y}=0.3282 + 2.1497X$\
절편(Intercept) $b_0$는 Coefficients:Estimate의 Intercept 값이고, \
기울기(Slope) $b_1$는 Coefficients:Estimate의 X값이다.\



**산점도(scatterplot)와 회귀직선 그리기**\
```{r}
plot(market$X, market$Y, xlab="광고료", ylab="총판매액", pch=10, main="광고료와 판매액의 산점도")
abline(market.lm)
```


**잔차(residual)**\
적합된 회귀직선 $\hat{Y}=b_0+b_1X$에서 $X$대신에 $i$번째 $X$값 $X_i$를 사용하면 $\hat{Y}=b_0+b_1X_i$가 되는데, 여기서 $\hat{Y}_i$는 $X_i$에서의 기대값 $E(Y_i)$의 추정값이다. $X_i$에서 측정된 값 $Y_i$와 추정된 $\hat{Y}_i$와의 차이 $\epsilon_i = Y_i - \hat{Y}_i$를 잔차라고 부르며, 추정된 모형의 적합성 등에 널리 이용된다. 회귀계수 $b_0, b_1$이 최소제곱법에 의한 추정값이면 다음과 같이 흥미로운 성질이 성립된다.\

(1) 잔차들의 합은 0이다. 즉 $\sum\epsilon_i=0$\
(2) 잔차제곱의 합, $\sum\epsilon_i^2$은 최소가 된다. 이것은 최소제곱법에 의하여 $b_0$와 $b_1$을 구할 때 요구된 성질이므로 명백하다.\
(3) 관찰값 $Y_i$의 합과 추정값 $\hat{Y}_i$의 합은 같다. 즉, $\sum Y_i=\sum\hat{Y}_i$이는 $\sum \epsilon_i = \sum Y_i -\sum\hat{Y}_i=0$이므로 명백하다.\
(4) 잔차들의 $X_i$에 의한 가중값은 0이다. 즉, $\sum X_i\epsilon_i = 0$\
(5) 잔차들의 $\hat{Y}_i$에 의하 가중값은 0이다. 즉, $\sum \hat{Y}_i\epsilon_i = 0$ 여기서 
$$\begin{matrix}\sum \hat{Y}_i\epsilon_i &=& \sum(b_0+b_1X_i)\epsilon_i \\
&=&b_0\sum\epsilon_i + b_1\sum X_i\epsilon_i \\
&=&0 \end{matrix}$$ 
임을 쉽게 알 수 있다.\
(6) 점 ($\bar{X}, \bar{Y}$)는 적합된 회귀선상에 있다. 이는 식 
$\hat{Y} = \bar{Y} + b_1(X_i-\bar{X})$에서 ($\bar{X}, \bar{Y}$)가 회귀선상에 있음이 명백하다.\

```{r}
# 파일 읽기 및 linear model 값
market = read.table("./data/market-1.txt", header = T)
market.lm = lm(Y~X, data=market)

# 어떤 변수들이 있는지 확인 및 resid, fitted(Y의 추정값) 변수에 저장
names(market.lm)
resid=market.lm$residuals
fitted=market.lm$fitted.values
# sum(resid) 결과값이 책과는 다르다 하지만 0.00000000 수준으로 0에 가깝기 때문에 0으로 간주하면 동일한 결과로 보면 될것 같다.
sum(resid)
# sum(fitted)와 sum(market$Y)의 값은 동일
sum(fitted);sum(market$Y)
# 잔차들의 X에 의한 가중합 = 0에 가깝다
sum(market$X*resid)
#잔차들의 Y에 의한 가중합 = 0에 가깝다.
sum(fitted*resid)
```

## 회귀모형의 정도

**분산분석표에 의한 F-검정**\

| 요인 | 자유도 | 제곱합 | 평균제곱 | $F_0$ | $Pr(>F)$ |
| :---: | :---: |  :---: |  :---: | :---: |  :---: |
| 회귀 | 1 | SSR | $MSR = \frac{SSR}{1}$ | $\frac{MSR}{MSE}$ |  |
| 잔차 | n-2 | SSE | $MSE = \frac{SSE}{n-2}$ |   |   |
| 계 | n-1 | SST |   |   |   |

```{r}
# 파일 읽기 및 linear model 값
market = read.table("./data/market-1.txt", header = T)
market.lm = lm(Y~X, data=market)
anova(market.lm)
```
자유도: DF, 제곱합: sum Sq, 평균제곱: mean Sq, $F_0$: F value, $Pr(>F)$: Pr(>F), \
SST = SSR + SSE\
결정계수 $R^2 = 485.57 / ( 485.57 + 32.72) = 0.9368$로 이는 총변동 중 회귀직선에 의하여 설명되는 부분이 93.68%라는 의미로서, 추정된 회귀선의 상관관계 정도가 높다는 것을 알 수 있음.\

분산분석결과해석:  \
p-값이 $3.554e-09$로 매우 작은 값이므로 귀무가설 $H_0:\beta_1=0$을 기각.\
참고 1: 유의수준 0.05에서 F-기각역
```{r}
# F-분포 분위함수 : qf(1-알파, 회귀 자유도, 잔차 자유도) ? 기각역 부분...
qf(0.95,1,13)
```
192.9 > 4.667193 이기 때문에 귀무가설을 기각함.\
참고 2: p-값 구하기\
```{r}
# P-값 누적 분포 함수 : 오른쪽 95% ~ 100% 범위이기 때문에 1에서 빼줘야 왼쪽 부분의 면적이 됨.
1-pf(192.9, 1, 13)
```
분산 분석표에서 $Pr(>F)$값과 동일


**결정계수(coefficient of determination)**\
총변동을 설명하는 데 있어서 회귀선에 의하여 설명되는 변동이 기여하는 비율을 의미하므로 ***회귀선의 기여율***이라고 부르기도함. 
$$R^2=\frac{SSR}{SST} = 1 - \frac{SSE}{SST} \\
SSE = \sum (Y_i - \hat{Y}_i)^2, SSR = \sum (\hat{Y}_i - \bar{Y})^2, \\
SST = SSE + SSR = \sum (Y_i - \bar{Y})^2$$
: 총 변동중에서 회귀선에 의하여 설명되는 비율이며 $R^2$의 범위는 $0 \le R^2 \le 1$임.\
$X$와 $Y$사이에 높은 상관관계가 있을수록 $R^2$의 값은 1에 가까워짐. 즉, $R^2$의 값이 0에 가까운 값을 가지는 회귀선은 쓸모가 없는 회귀선으로 유용성이 낮다.\


**추정값의 표준오차**\
분산분석표에서 잔차평균제곱 $MSE$는 오차분산 $\sigma^2$의 불편추정량이 됨. 따라서 $MSE$의 제곱근을 추정값의 표준오차(standard error of estimate)라고 부른다.\

```{r}
# 파일 읽기 및 linear model 값
market = read.table("./data/market-1.txt", header = T)
market.lm = lm(Y~X, data=market)
summary(market.lm)
```

Residual standard error: 1.587 \
$MSE = SSE / ( n-2) = 2.52$(anova 결과에서 residuals의 mean Sq)\
$S_{Y\cdot X}=\sqrt{MSE}=\sqrt{2.52}=1.587$


**상관계수와 결정계수 관계**\
*상관계수*: 상관계수는 두 연속인 변수간의 선형관계가 어느정도인가를 재는 측도 $r=\frac{S_{XY}}{\sqrt{S_{XX} S_{YY}}}$\
단순회귀분석에서는 상관계수 r을 다음과 같이 구할 수 있다. $r=\pm \sqrt{R^2}$ 즉, 상관계수는 결정계수 $R^2$의 제곱근이며, 만약 추정된 회귀서의 기울기 $b_1$이 양이면 $r=\sqrt{R^2}$으로 양의 상관계수를 갖고, $b_1$이 음이면 $r=-\sqrt{R^2}$으로 음의 상관관계를 가짐.

## $\beta_1$의 신뢰구간
- 회귀계수 기울기 $\beta_1$에 대한 추정량 \
$b_1=\frac{S_{XY}}{S_{XX}}= \frac{\sum(X_i-\bar{X})(Y_i-\bar{Y})}{\sum(X_i-\bar{X})^2}$ \
- 기댓값, 분산\
$E(b_1)=\beta_1$\
$Var(b_1)=\frac{\sigma^2}{S_{XX}} = \frac{\sigma^2}{\sum(X_i-\bar{X})^2}$\
- $\sigma^2$의 추정값은 $MSE$에 의하여 구해짐 $\hat{\sigma^2}=MSE$\
- $b_1$의 분산의 추정값\
$\hat{Var}(b_1)=\frac{MSE}{S_{XX}}$\
- $\beta_1$의 신뢰계수 $100(1-\alpha)$% 신뢰구간\
$b_1 \pm t(n-2;\alpha/2)\sqrt{\frac{MSE}{S_{XX}}}$
- 절편 $\beta_0$의 추정량\
$b_0=\bar{Y}-b_1\bar{X}$\
- 기댓값 및 분산\
$E(b_0)=\beta_0$\
$Var(b_0)=\sigma^2(\frac{1}{n}+\frac{\bar{X^2}}{S_{XX}})$\
- $\beta_0$의 $100(1-\alpha)$% 신뢰구간\
$b_0\pm t(n-1;\alpha/2) \sqrt{MSE(\frac{1}{n}+\frac{\bar{X^2}}{S_{XX}})}$

**R 결과에서 $\beta_1, \beta_0$ 신뢰구간 구하기**\
```{r}
market.lm = lm(Y~X,data = market)
market.anova = anova(market.lm)
(market.summary=summary(market.lm))
```
\
*$\beta_1$의 95% 신뢰구간*\
$X$의 추정값 $\pm$ 자유도가 $n-2, \alpha/2$인 $t$분포값 * `Residual standard error` 값
```{r}
(q.val = qt(0.975, 13))
c(2.1497-q.val*0.1548, 2.1497+q.val*0.1548)

# 2.1497 : X의 추정값
X_hat = market.summary$coefficients[2,1]
# 0.1548
X_std.error = market.summary$coefficients[2,2]

# 다시 수식을 이용해서 계산해보면
alpha = 0.05; n = length(market$Y)
(q.val=qt(1-alpha/2, 13))
c(X_hat-q.val*X_std.error, X_hat+q.val*X_std.error)
```
*$\beta_0$의 95% 신뢰구간*\
```{r}
# q.val값은 동일하여 새로 구하지 않는다.
# Intercept_hat : 절편의 추정값
I_hat = market.summary$coefficients[1,1]
# 절편의 잔차값
I_std.error = market.summary$coefficients[1,2]
c(I_hat-q.val*I_std.error, I_hat+q.val*I_std.error)
```


### 추정값에 대한 신뢰구간 내용 정리는 나중에

*X의 주어진 값에서 신뢰대 그리기*\

```{r}
pred.frame = data.frame(X=c(3.5,14.5))
pc = predict(market.lm, int="c", newdata=pred.frame); head(pc,3)
pp = predict(market.lm, interval = "p", newdata=pred.frame); head(pp,3)

plot(market$X, market$Y, ylim=range(market$Y, pp))
# matrix line, lty : line type 1 직선, 2 점선, 3 더 작은 점선
matlines(pred.frame$X, pc, lty = c(1,2,2), col="BLUE")
matlines(pred.frame$X, pp, lty = c(1,3,3), col="RED")

```



*$\beta_1$검정*\

```{r}
# t-value : X의 Estimate / Std.Error 
market.summary$coefficients[2,1]/market.summary$coefficients[2,2]
# X의 t-value
(t_0=market.summary$coefficients[2,3])

# 유의수준 0.05 기각역
alpha = 0.05; n = length(market$Y)
(q.val=qt(1-alpha/2, 13))
# 유의확률 값 : 직접 구하는 방법
2*(1-pt(t_0, 13))
# 유의확률 값 : summary에서 가져오는 방법
(p.value=market.summary$coefficients[2,4])

```

## 가중회귀

**가중최소제곱법**\
오차항마다 분산이 다른 경우 가중최소제곱법을 사용하여 회귀분석하는 것을 가중회귀

```{r}
x = c(1,2,3,4,5)
y = c(2,3,5,8,7)
w = 1/x
w.lm  = lm(y~x, weights=w)
(w.lm.summary = summary(w.lm))

```
## 분석사례
```{r}
# 자료 읽기
super = read.table("./data/supermarket.txt", header = T)
head(super, 3)
# 객체의 변수를 객체없이 접근하기 위해서 attach
attach(super)
# 산점도를 그린다.
plot(price,time,pch=19, xlab="금액", ylab="소요시간", main="마켓 산점도")

# 회귀모형 적합
super.lm = lm(time~price, data=super)
(super.summary = summary(super.lm))

```
- 단순회귀방정식 : $\hat{time}=0.3965 + 0.1160 \times price$\
- 기울기검정: price의 t-값은 12.92이고 p-값은 1.22e-06=0.0000122 값이 매우 작으므로 $H_0:\beta_1=0$이라는 귀무가설을 기각.\
- 결정계수 $R^2=0.9542$로서, 총변동 중에서 95.42%가 회귀방정식으로 설명되는 회귀변동이 차지하고 있다는 것을 나타냄\
- F-값:166.9이고, 이에대한 p-값=1.221e-06으로서 적합된 회귀직선이 유의하다는 것을 알수있다.\

*분산분석표*\
```{r}
(super.anova=anova(super.lm))
```
분산분석표에서 보면 검전통계량 $F_0=166.85$이고, 이에대한 p-값=1.221e-06으로서 적합된 회귀직선이 유의하다는 것을 알수있다.\
*잔차 및 추정값보기*\
```{r}
names(super.lm)
cbind(super, super.lm$resid, super.lm$fitted)
```
*잔차 그림 그리기*\
```{r}
plot(super$price, super.lm$resid, pch=19)
abline(h=0, lty=2)
```
*추정값의 신뢰대 그리기*\
```{r}
p.x = data.frame(price=c(1,45))
pc = predict(super.lm, int="c", newdata = p.x)
plot(super$price, super$time, ylim=range(super$time, pc), pch=19)
matlines(p.x$price, pc, lty=c(1,2,2), col="BLUE")
```




### 회귀모형 정리
```{r}
# market-1.txt 파일을 읽어서 
# 파일 읽기 및 linear model 값
market = read.table("./data/market-1.txt", header = T)
market.lm = lm(Y~X, data=market)
summary(market.lm)
```



