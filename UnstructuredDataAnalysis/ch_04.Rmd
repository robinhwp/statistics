---
title: "비정형데이터분석_4장"
author: "robinhwp"
date: "2023-12-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 4장 실습

```{r}
# Bag of words
x <- c('Kim was loved by everybody.', 'Everybody loved Kim','Kim loved everybody.')
str_df = strsplit(x, split=" ")


# tokenization
sub(pattern = "ouse", replacement = "ay", x = "mouse in the house")
gsub(pattern = "ouse", replacement = "ay", x = "mouse in the house")

#2-1
contraction_dict <- list(c("don't", "it's", "you're"), c("do not", "it is", "you are"))
dictlen <- length(contraction_dict[[1]]) # 축약된 표현의 수 

datstr <- "I don't think you're ready."
for (stri in 1:dictlen) {
       datstr <- gsub(pattern = contraction_dict[[1]][stri],
         replacement = contraction_dict[[2]][stri], x = datstr) 
  }   

datstr

strsplit(datstr, " ")



# 2-2
ngram_dict <- list(c("bed and breakfast", "grab and go", "New York"), c("bed_and_breakfast", "grab_and_go", "New_York"))

ndictlen <- length(ngram_dict[[1]]) # 관용어구 수
datstr <- "It's one of the best bed and breakfast in New York."
for (stri in 1:ndictlen) {
       datstr <- gsub(x=datstr, pattern=ngram_dict[[1]][stri],
           replacement = ngram_dict[[2]][stri]) 
 }       # 관용어구를 하나의 토큰으로 변환

datstr

strsplit(datstr, " ")

# 대소문자 변환
x <- c("Kim was a 12-year-old boy.", "It's 11 O'clock.",
          "Everybody loved Kim.")
tolower(x)
toupper(x)


# 문장 부호의 삭제
x <- c("Kim was a 12-year-old boy!", "It's 11 O'clock.",
          "Everybody loved KIM.")
gsub(x, pattern = "([[:punct:]])", replacement = "")
gsub(x, pattern = "([^[:alnum:][:blank:]'-])", replacement = "") 
# [ ] 내 문자,숫자,어퍼스트로피,공백,줄표는  삭제하지 않음
gsub(x, pattern = "[[:upper:]][[:lower:]'^[:upper:]]", replacement = "\\L\\1\\2", perl = TRUE)


gsub("(^[[:upper:]][^[:upper:]])", replacement = "\\L\\1\\2", x, perl = TRUE)


# 어간추출
# install.packages("textstem")

library(textstem)
txts = c("The Williams sisters are leaving this tennis centre.")
stem_strings(txts, language = "porter")

# 원형복원
lemmatize_strings(txts)

# 불용어 삭제 
install.packages("stopwords")
library(stopwords)
txt = c("He decided to quit this job.", "I do not deny it.", "Can you hear me?")
txt = tolower(txt)
txt = gsub(txt, pattern = "([^[:alnum:][:blank:]'-])", replacement="")
txt = strsplit(txt, " ")
lapply(txt, setdiff, y=stopwords())

newstop <- c(stopwords(), "can") # 제거목록에 "can"추가
newstop <- setdiff(newstop, c("no", "not"))
               # 새로운 제거목록 newstop에서 "no", "not" 제외
lapply(txt, setdiff, y=newstop)



# 실제 데이터의 전처리
RC <- scan("http://www.gutenberg.org/files/521/521-0.txt", what = "character",  encoding = "UTF-8", sep = "\n")
RC_Chpt <- grep(RC, pattern="CHAPTER") #각 장 시작 위치
RC_End <- grep(RC, pattern="END OF THE PROJECT GUTENBERG EBOOK",ignore.case=T)-1 # 본문이 끝나는 위치 정보 추출
RC_body <- RC[(RC_Chpt[1]):RC_End]
RC_all <- paste(RC_body, collapse = " ")# 각 행들 연결 
RC_all <- gsub(RC_all, pattern = "'s", replacement = "")
RC_all <- gsub(RC_all, pattern = "([^[:alnum:][:blank:]'-])", replacement = "") 
#부호제거
RC_all <- tolower(RC_all) # 소문자로 변환
RC_all <- unlist(strsplit(RC_all, " ")) #리스트→벡터
library(stopwords)
RC_all2 = RC_all[! RC_all %in% c(stopwords(), "")]
library(textstem)
RC_all <- lemmatize_strings(RC_all) # 원형복원
RC_all_table <- sort(table(RC_all), decreasing = T)
RC_all_proptable <- sort(prop.table(table(RC_all)), decreasing=T)  # 도수분포표 및 상대도수분포표

# 5장 연습 내용 추가
library(tidytext)
bingsent = get_sentiments("bing")
bingpos = bingsent[bingsent$sentiment == "positive",]
bingneg = bingsent[bingsent$sentiment == "negative", ]

# bingpos 1 ~ 31 까지의 데이터 확인
colnames(bingpos)
bingpos$word[1:31]

```


